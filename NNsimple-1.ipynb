{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aec01c69-10ff-4511-b1bd-9868bd9a817a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:56:08.123013Z",
     "start_time": "2024-07-26T21:56:07.843141Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57a0d0a3-bce8-4c38-8519-de438453d9c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:56:12.606188Z",
     "start_time": "2024-07-26T21:56:12.603050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funcion de activacion\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "116b55fd-9a7a-4b44-9539-d4872bbe498c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T22:00:09.240146Z",
     "start_time": "2024-07-26T22:00:09.228378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializacion de los parametros\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x)\n",
    "    b1 = np.random.randn(n_h, 1)\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.random.randn(n_y, 1)\n",
    "\n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\" : b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\" : b2\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6be7ae9-04d0-4d6a-9c01-5a7eac130dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:56:14.124719Z",
     "start_time": "2024-07-26T21:56:14.121429Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_prop(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = {\n",
    "        \"A1\": A1,\n",
    "        \"A2\": A2\n",
    "    }\n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9955bcc-5d7a-4835-92a3-e8a14b17075a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:59:21.621142Z",
     "start_time": "2024-07-26T21:59:21.608741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funcion de perdida\n",
    "def loss_function(A2, Y):\n",
    "    cost = -np.sum(np.multiply(Y, np.log(A2)) +  np.multiply(1-Y, np.log(1-A2)))/m\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c44babe6-3b89-4ae1-afa0-c0d67963db7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:59:00.143312Z",
     "start_time": "2024-07-26T21:59:00.135020Z"
    }
   },
   "outputs": [],
   "source": [
    "def backward_prop(X, Y, cache, parameters):\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "\n",
    "    W2 = parameters[\"W2\"]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T)/m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1-np.power(A1, 2))\n",
    "    dW1 = np.dot(dZ1, X.T)/m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
    "\n",
    "    grads = {\n",
    "        \"dW1\": dW1,\n",
    "        \"db1\": db1,\n",
    "        \"dW2\": dW2,\n",
    "        \"db2\": db2\n",
    "    }\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46551921-f9de-469c-803b-1d3178de2e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:56:16.164320Z",
     "start_time": "2024-07-26T21:56:16.160744Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "\n",
    "    new_parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"W2\": W2,\n",
    "        \"b1\" : b1,\n",
    "        \"b2\" : b2\n",
    "    }\n",
    "\n",
    "    return new_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d570771f-8737-448d-a26a-a29e6f0adb16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:59:14.094293Z",
     "start_time": "2024-07-26T21:59:14.087913Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(X, Y, n_x, n_h, n_y, num_of_iters, learning_rate):\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    cost_iteration = []\n",
    "\n",
    "    for i in range(0, num_of_iters+1):\n",
    "        a2, cache = forward_prop(X, parameters)\n",
    "\n",
    "        cost = loss_function(a2, Y)\n",
    "\n",
    "        grads = backward_prop(X, Y, cache, parameters)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        if(i%100 == 0):\n",
    "            print('Cost after iteration# {:d}: {:f}'.format(i, cost))\n",
    "            cost_iteration.append([i, cost])\n",
    "\n",
    "    return parameters, cost_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d18e70d-67e2-45b0-8fe6-25425837ce26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T21:56:19.879371Z",
     "start_time": "2024-07-26T21:56:19.874774Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    a2, cache = forward_prop(X, parameters)\n",
    "    yhat = a2\n",
    "    yhat = np.squeeze(yhat)\n",
    "    if(yhat >= 0.5):\n",
    "        y_predict = 1\n",
    "    else:\n",
    "        y_predict = 0\n",
    "\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d88cffb5-e998-4533-aa74-243088c76171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T22:00:12.409074Z",
     "start_time": "2024-07-26T22:00:12.354124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration# 0: 1.052558\n",
      "Cost after iteration# 100: 0.695402\n",
      "Cost after iteration# 200: 0.693668\n",
      "Cost after iteration# 300: 0.693206\n",
      "Cost after iteration# 400: 0.692966\n",
      "Cost after iteration# 500: 0.692779\n",
      "Cost after iteration# 600: 0.692587\n",
      "Cost after iteration# 700: 0.692352\n",
      "Cost after iteration# 800: 0.692030\n",
      "Cost after iteration# 900: 0.691539\n",
      "Cost after iteration# 1000: 0.690679\n",
      "{'W1': array([[-0.59247105, -0.47282144],\n",
      "       [-2.06763357, -0.23592616]]), 'W2': array([[-0.43995116, -0.16049007]]), 'b1': array([[-1.50109455],\n",
      "       [-1.77729809]]), 'b2': array([[-0.56827845]])}\n",
      "Neural Network prediction for example (1, 1) is 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "# The 4 training examples by columns\n",
    "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])\n",
    "\n",
    "# The outputs of the XOR for every example in X\n",
    "Y = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "# No. of training examples\n",
    "m = X.shape[1]\n",
    "\n",
    "# Set the hyperparameters\n",
    "n_x = 2     #No. of neurons in first layer\n",
    "n_h = 2     #No. of neurons in hidden layer\n",
    "n_y = 1     #No. of neurons in output layer\n",
    "num_of_iters = 1000\n",
    "learning_rate = 0.3\n",
    "\n",
    "trained_parameters, _ = model(X, Y, n_x, n_h, n_y, num_of_iters, learning_rate)\n",
    "\n",
    "# Test 2X1 vector to calculate the XOR of its elements.\n",
    "# Try (0, 0), (0, 1), (1, 0), (1, 1)\n",
    "X_test = np.array([[1], [1]])\n",
    "\n",
    "print(trained_parameters)\n",
    "\n",
    "y_predict = predict(X_test, trained_parameters)\n",
    "\n",
    "print('Neural Network prediction for example ({:d}, {:d}) is {:d}'.format(\n",
    "    X_test[0][0], X_test[1][0], y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e30b54",
   "metadata": {},
   "source": [
    "# Problema 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9ccb931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration# 0: 1.052558\n",
      "Cost after iteration# 100: 0.695402\n",
      "Cost after iteration# 200: 0.693668\n",
      "Cost after iteration# 300: 0.693206\n",
      "Cost after iteration# 400: 0.692966\n",
      "Cost after iteration# 500: 0.692779\n",
      "Cost after iteration# 600: 0.692587\n",
      "Cost after iteration# 700: 0.692352\n",
      "Cost after iteration# 800: 0.692030\n",
      "Cost after iteration# 900: 0.691539\n",
      "Cost after iteration# 1000: 0.690679\n",
      "Cost after iteration# 0: 0.693147\n",
      "Cost after iteration# 100: 0.693147\n",
      "Cost after iteration# 200: 0.693147\n",
      "Cost after iteration# 300: 0.693147\n",
      "Cost after iteration# 400: 0.693147\n",
      "Cost after iteration# 500: 0.693147\n",
      "Cost after iteration# 600: 0.693147\n",
      "Cost after iteration# 700: 0.693147\n",
      "Cost after iteration# 800: 0.693147\n",
      "Cost after iteration# 900: 0.693147\n",
      "Cost after iteration# 1000: 0.693147\n",
      "\n",
      "Trained parameters with random initialization\n",
      "{'W1': array([[-0.59247105, -0.47282144],\n",
      "       [-2.06763357, -0.23592616]]), 'W2': array([[-0.43995116, -0.16049007]]), 'b1': array([[-1.50109455],\n",
      "       [-1.77729809]]), 'b2': array([[-0.56827845]])}\n",
      "\n",
      "Trained parameters with zeros initialization\n",
      "{'W1': array([[0., 0.],\n",
      "       [0., 0.]]), 'W2': array([[0., 0.]]), 'b1': array([[0.],\n",
      "       [0.]]), 'b2': array([[0.]])}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Cost Random</th>\n",
       "      <th>Cost Zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.052558</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.693668</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>0.693206</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.692966</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.692779</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>0.692587</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>700</td>\n",
       "      <td>0.692352</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>800</td>\n",
       "      <td>0.692030</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>900</td>\n",
       "      <td>0.691539</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.690679</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iteration  Cost Random  Cost Zeros\n",
       "0           0     1.052558    0.693147\n",
       "1         100     0.695402    0.693147\n",
       "2         200     0.693668    0.693147\n",
       "3         300     0.693206    0.693147\n",
       "4         400     0.692966    0.693147\n",
       "5         500     0.692779    0.693147\n",
       "6         600     0.692587    0.693147\n",
       "7         700     0.692352    0.693147\n",
       "8         800     0.692030    0.693147\n",
       "9         900     0.691539    0.693147\n",
       "10       1000     0.690679    0.693147"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Inicialización aleatoria\n",
    "np.random.seed(2)\n",
    "\n",
    "trained_parameters_random, cost_iteration_random = model(X, Y, n_x, n_h, n_y, num_of_iters, learning_rate)\n",
    "\n",
    "# Inicialización en 0\n",
    "def initialize_parameters_zeros(n_x, n_h, n_y):\n",
    "    W1 = np.zeros((n_h, n_x))\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.zeros((n_y, n_h))\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2\n",
    "    }\n",
    "    return parameters\n",
    "\n",
    "# Ajuste en la función model\n",
    "def model_zeros(X, Y, n_x, n_h, n_y, num_of_iters, learning_rate):\n",
    "    parameters = initialize_parameters_zeros(n_x, n_h, n_y)\n",
    "    cost_iteration = []\n",
    "\n",
    "    for i in range(0, num_of_iters+1):\n",
    "        a2, cache = forward_prop(X, parameters)\n",
    "        cost = loss_function(a2, Y)\n",
    "        grads = backward_prop(X, Y, cache, parameters)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if(i % 100 == 0):\n",
    "            print('Cost after iteration# {:d}: {:f}'.format(i, cost))\n",
    "            cost_iteration.append([i, cost])\n",
    "\n",
    "    return parameters, cost_iteration\n",
    "\n",
    "trained_parameters_zeros, cost_iteration_zeros = model_zeros(X, Y, n_x, n_h, n_y, num_of_iters, learning_rate)\n",
    "\n",
    "cost_iterations_zipped = [x + y for x, y in zip(cost_iteration_random, cost_iteration_zeros)]\n",
    "\n",
    "df = pd.DataFrame(cost_iterations_zipped, columns=[\"Iteration\", \"Cost Random\", \"Iteration 2\", \"Cost Zeros\"])\n",
    "\n",
    "print()\n",
    "print(\"Trained parameters with random initialization\")\n",
    "print(trained_parameters_random)\n",
    "print(\"\\nTrained parameters with zeros initialization\")\n",
    "print(trained_parameters_zeros)\n",
    "print()\n",
    "\n",
    "df = df.drop(\"Iteration 2\", axis=1)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
